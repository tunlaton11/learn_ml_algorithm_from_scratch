{"cells":[{"cell_type":"markdown","id":"mysterious-smile","metadata":{"id":"mysterious-smile"},"source":["Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n","\n","Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and student id below:"]},{"cell_type":"code","execution_count":70,"id":"excited-navigator","metadata":{"id":"excited-navigator"},"outputs":[],"source":["NAME = \"Tunlaton Wongchai\"\n","STUDENT_ID = \"63070224\""]},{"cell_type":"markdown","id":"derived-diversity","metadata":{"id":"derived-diversity"},"source":["---"]},{"cell_type":"markdown","id":"valued-astronomy","metadata":{"deletable":false,"editable":false,"id":"valued-astronomy","nbgrader":{"cell_type":"markdown","checksum":"161f97b2eb24fc268c4cd40ea0c379fe","grade":false,"grade_id":"cell-87ba42be45cc1b64","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# 1 Digits Image Classification"]},{"cell_type":"markdown","id":"running-idaho","metadata":{"deletable":false,"editable":false,"id":"running-idaho","nbgrader":{"cell_type":"markdown","checksum":"9a95cbdc0697bdf8c06d7b12ce3a9c9c","grade":false,"grade_id":"cell-caffb96046e46f60","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.1 Load Digits dataset from sklearn library"]},{"cell_type":"code","execution_count":85,"id":"favorite-momentum","metadata":{"id":"favorite-momentum"},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","import sklearn\n","import matplotlib.pyplot as plt\n","from itertools import product\n","\n","digits = load_digits()\n","\n","X = digits['data']\n","y = digits['target']\n","\n","SEED = 0"]},{"cell_type":"markdown","id":"cutting-complex","metadata":{"deletable":false,"editable":false,"id":"cutting-complex","nbgrader":{"cell_type":"markdown","checksum":"b8273e7b408326e0e0a4996f1bbbb8e0","grade":false,"grade_id":"cell-201e752f3ffaadaa","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.2 Use sklearn train test split function to randomly split the dataset to training and test sets with test size = 0.3 and shuffle = True."]},{"cell_type":"code","execution_count":86,"id":"conventional-dubai","metadata":{"id":"conventional-dubai"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=SEED)"]},{"cell_type":"markdown","id":"unauthorized-cuisine","metadata":{"deletable":false,"editable":false,"id":"unauthorized-cuisine","nbgrader":{"cell_type":"markdown","checksum":"05aee8db93db9cad4238e04c7a9af739","grade":false,"grade_id":"cell-196ba86340c55a14","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.3 Train Support Vector Machine (SVM) models on this dataset by using one-vs-all scheme. SVMs settings are defined as follows:\n","\n","(i) Kernel Function: Linear Function and (ii) C hyperparameter: $[10^{−6}, 1, 10^{+6}]$. Report the training/test accuracy and the number of iteration used by each set of parameter and discuss the results. What do you observe when the parameters are varied?"]},{"cell_type":"code","execution_count":87,"id":"silent-yeast","metadata":{"deletable":false,"id":"silent-yeast","nbgrader":{"cell_type":"code","checksum":"73bba493d69313b65cf4645ba4767d81","grade":true,"grade_id":"cell-5d1937e67eeca004","locked":false,"points":3,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["C:  1e-06\n","Train accuracy: 0.2092283214001591\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C:  1\n","Train accuracy: 1.0\n","Test accuracy: 0.9740740740740741\n","------------------------------\n","C:  1000000.0\n","Train accuracy: 1.0\n","Test accuracy: 0.9740740740740741\n","------------------------------\n"]}],"source":["C_list = [1e-6, 1, 1e+6]\n","\n","for C in C_list:\n","    clf = svm.SVC(C=C, decision_function_shape='ovr', random_state=SEED, kernel='linear')\n","    clf.fit(X_train, y_train)\n","\n","    print('C: ', C)\n","    print(f'Train accuracy: {clf.score(X_train, y_train)}')\n","    print(f'Test accuracy: {clf.score(X_test, y_test)}')\n","    print('-'*30)"]},{"cell_type":"markdown","id":"diverse-january","metadata":{"deletable":false,"editable":false,"id":"diverse-january","nbgrader":{"cell_type":"markdown","checksum":"cc1b8cb03c434ce879f1dd878c66aa65","grade":false,"grade_id":"cell-6a50b9d4ef59d1b9","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.4 Train SVM models on this dataset by using one-vs-all scheme. SVMs settings are defined as follows:\n","\n","(i) Kernel Function: Radial Basis Function (RBF), Kernel Parameter: Gamma $[10^{−6}, 1, 10^{+6}]$, and (iii) C hyperparameter: $[10^{−6}, 1, 10^{+6}]$. Report the training/test accu- racy and the number of iteration used by each combination set of parameter and discuss the results. What do you observe when the parameters are varied?"]},{"cell_type":"code","execution_count":88,"id":"missing-silicon","metadata":{"deletable":false,"id":"missing-silicon","nbgrader":{"cell_type":"code","checksum":"bf85d97351c9ca0472cfd53a0e2fd4f5","grade":true,"grade_id":"cell-1b6be0d702b8ec72","locked":false,"points":3,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["C: 1e-06 | gamma: 1e-06\n","Train accuracy: 0.2092283214001591\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | gamma: 1\n","Train accuracy: 0.21161495624502785\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | gamma: 1000000.0\n","Train accuracy: 0.21161495624502785\n","Test accuracy: 0.08888888888888889\n","------------------------------\n","C: 1 | gamma: 1e-06\n","Train accuracy: 0.2092283214001591\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1 | gamma: 1\n","Train accuracy: 1.0\n","Test accuracy: 0.08888888888888889\n","------------------------------\n","C: 1 | gamma: 1000000.0\n","Train accuracy: 1.0\n","Test accuracy: 0.08888888888888889\n","------------------------------\n","C: 1000000.0 | gamma: 1e-06\n","Train accuracy: 1.0\n","Test accuracy: 0.9740740740740741\n","------------------------------\n","C: 1000000.0 | gamma: 1\n","Train accuracy: 1.0\n","Test accuracy: 0.08888888888888889\n","------------------------------\n","C: 1000000.0 | gamma: 1000000.0\n","Train accuracy: 1.0\n","Test accuracy: 0.08888888888888889\n","------------------------------\n"]}],"source":["C_list = [1e-6, 1, 1e+6]\n","gamma_list = [1e-6, 1, 1e+6]\n","\n","for C, gamma in product(C_list, gamma_list):\n","    clf = svm.SVC(C=C, gamma=gamma, decision_function_shape='ovr', random_state=SEED, kernel='rbf')\n","    clf.fit(X_train, y_train)\n","\n","    print(f'C: {C} | gamma: {gamma}')\n","    print(f'Train accuracy: {clf.score(X_train, y_train)}')\n","    print(f'Test accuracy: {clf.score(X_test, y_test)}')\n","    print('-'*30)"]},{"cell_type":"markdown","id":"sunrise-candy","metadata":{"deletable":false,"editable":false,"id":"sunrise-candy","nbgrader":{"cell_type":"markdown","checksum":"9f0a44a48c06762a12fd7357f1f0d22c","grade":false,"grade_id":"cell-b5f97abc424dbbe7","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.5 Train SVM models on this dataset by using one-vs-all scheme. SVMs settings are defined as follows:\n","\n","(i) Kernel Function: Polynomial Function, Kernel Parameter: Degree [1–6] and coef0=0, and (iii) C hyperparameter: $[10^{−6},1,10^{+6}]$. Report the training/test accuracy and the number of iteration used by each combination set of parameter and discuss the results. What do you observe when the parameters are varied?"]},{"cell_type":"code","execution_count":89,"id":"english-immigration","metadata":{"deletable":false,"id":"english-immigration","nbgrader":{"cell_type":"code","checksum":"90743cd42f0f0b81880dea22d4f7dcf4","grade":true,"grade_id":"cell-0e05421b125e84ef","locked":false,"points":3,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["C: 1e-06 | degree: 1\n","Train accuracy: 0.2092283214001591\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | degree: 2\n","Train accuracy: 0.21081941129673826\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | degree: 3\n","Train accuracy: 0.21081941129673826\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | degree: 4\n","Train accuracy: 0.21081941129673826\n","Test accuracy: 0.17222222222222222\n","------------------------------\n","C: 1e-06 | degree: 5\n","Train accuracy: 0.2052505966587112\n","Test accuracy: 0.16296296296296298\n","------------------------------\n","C: 1e-06 | degree: 6\n","Train accuracy: 0.18138424821002386\n","Test accuracy: 0.15\n","------------------------------\n","C: 1 | degree: 1\n","Train accuracy: 0.9856801909307876\n","Test accuracy: 0.9722222222222222\n","------------------------------\n","C: 1 | degree: 2\n","Train accuracy: 0.9952267303102625\n","Test accuracy: 0.987037037037037\n","------------------------------\n","C: 1 | degree: 3\n","Train accuracy: 0.9992044550517104\n","Test accuracy: 0.9888888888888889\n","------------------------------\n","C: 1 | degree: 4\n","Train accuracy: 1.0\n","Test accuracy: 0.9833333333333333\n","------------------------------\n","C: 1 | degree: 5\n","Train accuracy: 1.0\n","Test accuracy: 0.9777777777777777\n","------------------------------\n","C: 1 | degree: 6\n","Train accuracy: 1.0\n","Test accuracy: 0.9796296296296296\n","------------------------------\n","C: 1000000.0 | degree: 1\n","Train accuracy: 1.0\n","Test accuracy: 0.9740740740740741\n","------------------------------\n","C: 1000000.0 | degree: 2\n","Train accuracy: 1.0\n","Test accuracy: 0.9833333333333333\n","------------------------------\n","C: 1000000.0 | degree: 3\n","Train accuracy: 1.0\n","Test accuracy: 0.9796296296296296\n","------------------------------\n","C: 1000000.0 | degree: 4\n","Train accuracy: 1.0\n","Test accuracy: 0.9814814814814815\n","------------------------------\n","C: 1000000.0 | degree: 5\n","Train accuracy: 1.0\n","Test accuracy: 0.9796296296296296\n","------------------------------\n","C: 1000000.0 | degree: 6\n","Train accuracy: 1.0\n","Test accuracy: 0.9777777777777777\n","------------------------------\n"]}],"source":["C_list = [1e-6, 1, 1e+6]\n","degree_list = list(range(1, 7))\n","\n","for C, degree in product(C_list, degree_list):\n","    clf = svm.SVC(C=C, degree=degree, decision_function_shape='ovr', random_state=SEED, kernel='poly')\n","    clf.fit(X_train, y_train)\n","\n","    print(f'C: {C} | degree: {degree}')\n","    print(f'Train accuracy: {clf.score(X_train, y_train)}')\n","    print(f'Test accuracy: {clf.score(X_test, y_test)}')\n","    print('-'*30)"]},{"cell_type":"markdown","id":"challenging-blocking","metadata":{"deletable":false,"editable":false,"id":"challenging-blocking","nbgrader":{"cell_type":"markdown","checksum":"ae19663207102631f71ed2cde7c368db","grade":false,"grade_id":"cell-9c71e98c7a1f0bcc","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.6 Compare the results of the three kernels used in the previous questions. What do you observe? Are there any cases (set of parameters) that can lead model to be over-fitted? If there are, can you explain why did it happen?"]},{"attachments":{},"cell_type":"markdown","id":"boring-engine","metadata":{"deletable":false,"id":"boring-engine","nbgrader":{"cell_type":"markdown","checksum":"ca004c9625873bceb3af8aa01fa33d21","grade":true,"grade_id":"cell-dcde510bad17115b","locked":false,"points":5,"schema_version":3,"solution":true,"task":false}},"source":["- ที่ linear kernel : พบว่าที่ค่า C ต่ำๆ จะทำให้ model เกิดการ over-fitted\n","- ที่ rbf kernel : พบว่าที่ค่า gamma มากๆ จะทำให้ model เกิดการ over-fitted\n","- ที่ polynomial kernel : พบว่าที่ค่า degree ต่ำๆ จะทำให้ model เกิดการ over-fitted"]},{"cell_type":"markdown","id":"spread-armor","metadata":{"deletable":false,"editable":false,"id":"spread-armor","nbgrader":{"cell_type":"markdown","checksum":"cee263b8754d7dae45df3fd22ee0be5c","grade":false,"grade_id":"cell-852082bd148d76e7","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.7  Find the optimal model that gives the best m-fold cross-validation accuracy on the training set and report the test accuracy. Feel free to select range and step of each parameter by yourself. Also illustrate how each parameter effects the accuracy of the model.\n","\n","For example (not that it's the correct version):\n","\n","![SVM Accuracy](https://bit.ly/3fcngt1)"]},{"cell_type":"code","execution_count":76,"id":"mounted-controversy","metadata":{"deletable":false,"id":"mounted-controversy","nbgrader":{"cell_type":"code","checksum":"b7cfd7e81fe1c46f664a7b8242266acc","grade":true,"grade_id":"cell-3e5ee2ec07df8233","locked":false,"points":7,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["from dataclasses import dataclass\n","from typing import Literal, List\n","\n","C_list = [10**x for x in np.arange(-6, 2, 0.2)]\n","kernel_list = ['linear', 'poly', 'rbf']\n","\n","Kernel = Literal['linear', 'poly', 'rbf']\n","\n","@dataclass\n","class Result:\n","    C:int\n","    kernel: Kernel\n","    acc: int\n","\n","results = []\n","\n","for C, kernel in product(C_list, kernel_list):\n","    clf = svm.SVC(C=C, decision_function_shape='ovr', random_state=SEED, kernel=kernel)\n","    result = Result(\n","        C=C,\n","        kernel=kernel,\n","        acc=np.mean(cross_val_score(clf, X_train, y_train, cv=5))\n","    )\n","    results.append(result)"]},{"cell_type":"code","execution_count":77,"id":"decimal-canon","metadata":{"deletable":false,"id":"decimal-canon","nbgrader":{"cell_type":"code","checksum":"cc1c898d56fa6fa5e4cc909511acd001","grade":true,"grade_id":"cell-a9fafdee05708382","locked":false,"points":7,"schema_version":3,"solution":true,"task":false}},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["def plot_result(results: List[Result], kernel: Kernel):\n","    results = [result for result in results if result.kernel == kernel]\n","    plt.xscale('log')\n","    plt.plot([r.C for r in results], [r.acc for r in results])\n","\n","for kernel in kernel_list:\n","    plot_result(results, kernel)\n","\n","plt.legend(kernel_list)\n","plt.show()"]},{"cell_type":"markdown","id":"incorrect-bidder","metadata":{"deletable":false,"editable":false,"id":"incorrect-bidder","nbgrader":{"cell_type":"markdown","checksum":"1e143895e5609457ca834cf7b3a7545b","grade":false,"grade_id":"cell-02fe9552506725d0","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.8 Solve this problem with Logistic Regression. Similarly to the previous task, one-vs-all scheme is employed, multi class = ‘ovr’, and solver = ‘liblinear’. Observe the results and report the accuracy."]},{"cell_type":"code","execution_count":78,"id":"quick-hygiene","metadata":{"deletable":false,"id":"quick-hygiene","nbgrader":{"cell_type":"code","checksum":"e5c977e2f13011f5dfadda7500583d39","grade":true,"grade_id":"cell-853cd447e60fc3a5","locked":false,"points":3,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["Train accuracy: 0.9976133651551312\n","Test accuracy: 0.9537037037037037\n"]}],"source":["clf = LogisticRegression(random_state=SEED, multi_class='ovr', solver='liblinear')\n","clf.fit(X_train, y_train)\n","print(f'Train accuracy: {clf.score(X_train, y_train)}')\n","print(f'Test accuracy: {clf.score(X_test, y_test)}')"]},{"cell_type":"markdown","id":"unauthorized-balloon","metadata":{"deletable":false,"editable":false,"id":"unauthorized-balloon","nbgrader":{"cell_type":"markdown","checksum":"c61a8817b886dcf79af867b0cf24734c","grade":false,"grade_id":"cell-14a62c7084d0d4f5","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 1.9 Compare the results obtained by Logistic Regression to SVM with all three kernels. Observe and discuss on the results. If the results obtained from Logistic Regression are not inline with SVM with kernels, how will you solve the problem? Explain why the results of SVM and Logistic Regression should be inlined?"]},{"attachments":{},"cell_type":"markdown","id":"recreational-savannah","metadata":{"deletable":false,"id":"recreational-savannah","nbgrader":{"cell_type":"markdown","checksum":"f73675814c78cda6d96467568e88bc77","grade":true,"grade_id":"cell-903ce89649d4a33f","locked":false,"points":5,"schema_version":3,"solution":true,"task":false}},"source":["logistic regression ให้ผลลัพธ์ใกล้เคียงกับ svm ที่เป็น linear kernel หรือ polynomial degree 1 เนื่องจาก decision boundary เป็นแบบ linear ผลลัพธ์จึงไม่ต่างกันมาก"]},{"cell_type":"markdown","id":"nonprofit-session","metadata":{"deletable":false,"editable":false,"id":"nonprofit-session","nbgrader":{"cell_type":"markdown","checksum":"753a9f6d1778bff1961e139910d6ef98","grade":false,"grade_id":"cell-709b243861adf890","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# 2 Iris Classification"]},{"cell_type":"markdown","id":"sporting-painting","metadata":{"deletable":false,"editable":false,"id":"sporting-painting","nbgrader":{"cell_type":"markdown","checksum":"b4d46febbf676bc47ebf26216d011e02","grade":false,"grade_id":"cell-30699e04166b6d17","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 2.1 Load Iris dataset from sklearn library"]},{"cell_type":"code","execution_count":91,"id":"suspended-andorra","metadata":{"id":"suspended-andorra"},"outputs":[{"data":{"text/plain":["array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["iris = sklearn.datasets.load_iris()\n","iris['target_names']"]},{"cell_type":"markdown","id":"physical-combining","metadata":{"deletable":false,"editable":false,"id":"physical-combining","nbgrader":{"cell_type":"markdown","checksum":"0b6bb84111db73b14e7274b6c32c458a","grade":false,"grade_id":"cell-51a2df6f1b2fa94d","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 2.2 Define Setal Length (cm), Setal Width (cm),petal length (cm) and petal width (cm) as X, Label—0 (Setosa), 1 (Versicolor) and 2 (Virginica) as y\n"]},{"cell_type":"code","execution_count":92,"id":"honest-lancaster","metadata":{"id":"honest-lancaster"},"outputs":[],"source":["data_idx = np.where(np.logical_or(iris['target'] == 0, iris['target']==1))[0]\n","\n","# X = Sepal Length (cm), Sepal Width (cm)\n","X = iris['data'][data_idx, :]\n","\n","# y = Setosa, Versicolor\n","y = iris['target'][data_idx]"]},{"cell_type":"markdown","id":"magnetic-adjustment","metadata":{"deletable":false,"editable":false,"id":"magnetic-adjustment","nbgrader":{"cell_type":"markdown","checksum":"f13684520457958bd410adb014662c39","grade":false,"grade_id":"cell-68cf07b0c055b526","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 2.3 Use sklearn train test split function to randomly split the dataset to training and test sets with test size = 0.3 and shuffle = True."]},{"cell_type":"code","execution_count":93,"id":"partial-snapshot","metadata":{"id":"partial-snapshot"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=SEED)"]},{"cell_type":"markdown","id":"rough-offset","metadata":{"deletable":false,"editable":false,"id":"rough-offset","nbgrader":{"cell_type":"markdown","checksum":"beef87920f6e71e522d2a3715a70bc97","grade":false,"grade_id":"cell-ee4dca20a07b228b","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### 2.4 Train SVM models on this dataset by using one-vs-all scheme. Linear kernel is employed and C is set to 1. Observe and report the results. In addition, plot the feature importance of each feature obtained by SVM (weights that correspond to all features). Discuss on what you have observed. Can we illustrate feature importance from SVM with other kernels (i.e., RBF, Polynomial).\n","\n","For example (not that it's the correct version):\n","\n","![Importance](https://bit.ly/3fejuPx)"]},{"cell_type":"code","execution_count":94,"id":"a722a61d","metadata":{},"outputs":[],"source":["def feature_importance(coef, names):\n","    importance, name = zip(*sorted(zip(coef, names)))\n","    plt.barh(range(len(names)), importance, align='center')\n","    plt.yticks(range(len(names)), names)\n","    plt.show()"]},{"cell_type":"code","execution_count":101,"id":"satisfactory-facial","metadata":{"deletable":false,"id":"satisfactory-facial","nbgrader":{"cell_type":"code","checksum":"5395d4ccdb1fb7f621e96b86ff3b3c33","grade":true,"grade_id":"cell-29028f601e315929","locked":false,"points":3,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["Train accuracy: 1.0\n","Test accuracy: 1.0\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["clf = svm.SVC(decision_function_shape='ovr', random_state=SEED, kernel='linear')\n","clf.fit(X_train, y_train)\n","\n","print(f'Train accuracy: {clf.score(X_train, y_train)}')\n","print(f'Test accuracy: {clf.score(X_test, y_test)}')\n","\n","plt.title(\"Linear kernel\")\n","feature_importance(clf.coef_[0], iris['feature_names'])\n"]},{"attachments":{},"cell_type":"markdown","id":"double-wonder","metadata":{"deletable":false,"id":"double-wonder","nbgrader":{"cell_type":"markdown","checksum":"2be17856539f3d0eee5c91f255a5fffd","grade":true,"grade_id":"cell-036dbacb405467ff","locked":false,"points":5,"schema_version":3,"solution":true,"task":false}},"source":["petal width เป็น feature ที่สำคัญที่สุด และเมื่อใช้ kernel อื่นๆ (rbf, poly) จะไม่แสดง feature importance ได้ เนื่องจาก ไม่สามารถแสดงค่า coefficient"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"lab-9-support-vector-machine.ipynb","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":5}
